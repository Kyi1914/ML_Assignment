{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #helper\n",
    "from torch.utils.data import DataLoader # batching\n",
    "from torchvision import datasets, transforms # loading dataset\n",
    "from torchvision.utils import make_grid # for visualization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10aa7b330>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to help serve as cross validation in deep learning\n",
    "torch.manual_seed(47) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some transforms (convert 0-255 to 0-1)\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# if you want to crop the image, rotate the image; they are all done in this transform.\n",
    "\n",
    "# use pytorch dataset to load <MNIST - dataset of digit image>.\n",
    "\n",
    "# train\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "\n",
    "#validation set\n",
    "train_set, val_set = torch.utils.data.random_split(train_data, [50000,10000])\n",
    "\n",
    "#test\n",
    "test_data = datasets.MNIST (root = 'data', train=True, download= True, transform= transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 1: stochastic\n",
    "# if set train_loader => batch_size = 50000 - batch\n",
    "# if set val_loader => batch_size = 10000\n",
    "# if set test_loader => batch_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader (train_set, batch_size =64, shuffle=True)\n",
    "val_loader   = DataLoader (val_set,   batch_size =64, shuffle=True)\n",
    "test_loader  = DataLoader (test_data, batch_size =64, shuffle= False) # because no training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader) # 782 * 64 = 50048 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape )\n",
    "# 64 images, 1 channel, 28 width, 28 height\n",
    "print (labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.2510, 0.5020, 0.5020, 0.5020, 0.5020, 0.7490, 0.7490, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.7490, 1.0000, 1.0000, 0.7490, 0.7490, 1.0000, 1.0000, 1.0000,\n",
       "          0.7490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.5020, 0.2510, 0.0000, 0.7490, 0.2510, 1.0000, 1.0000,\n",
       "          1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000,\n",
       "          0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 1.0000,\n",
       "          0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000,\n",
       "          0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000,\n",
       "          0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000,\n",
       "          0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2510, 1.0000, 1.0000,\n",
       "          0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.7490, 1.0000, 0.5020, 0.5020, 1.0000, 1.0000,\n",
       "          0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.5020, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.2510, 0.2510, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "          1.0000, 0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000,\n",
       "          0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000,\n",
       "          0.5020, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 1.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 0.5020,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 1.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.7490, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7490, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first image\n",
    "images[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "the_image = images[0]\n",
    "# the_image is channel,height, width, we will transform h,w,channel: use transpose\n",
    "the_image = np.transpose(the_image, (1,2,0))\n",
    "plt.figure(figsize=(3,2))\n",
    "plt.imshow(the_image)\n",
    "\n",
    "labels[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape #input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the relationship between the input and convolutional layer and output\n",
    "\n",
    "layer1 = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, stride = 1, padding=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$0 = \\frac{I-F+2P}{S} + 1$$\n",
    "\n",
    "I = image width/height, F = filter size, P = padding, S = stride, O = output width/height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to pass something in to this layer\n",
    "out = layer1(images)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape for my Conv2d Layers\n",
    "layer1 = nn.Conv2d (1,  5, 3, 1, 1)\n",
    "layer2 = nn.Conv2d (5, 10, 3, 1, 1)\n",
    "\n",
    "out = layer2(layer1(images))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 120])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_3 = nn.Linear(10*28*28, 120)\n",
    "out = out.reshape (-1, 10* 28 *28)\n",
    "out.shape\n",
    "\n",
    "out2 = layer_3(out)\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7840"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10*28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kyi_CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self): # init all parameters and layers\n",
    "        super().__init__() # inherit everything from nn.Module\n",
    "        self.layer1 = nn.Conv2d (1,  5, 3, 1, 1)\n",
    "        self.layer2 = nn.Conv2d (5, 10, 3, 1, 1)\n",
    "        # predict\n",
    "        self.layer3 = nn.Linear(10* 28 * 28, 120)\n",
    "        self.layer4 = nn.Linear(120, 84)\n",
    "        self.layer5 = nn.Linear(84, 10) # why 10? because 10 classes\n",
    "        \n",
    "    def forward(self, images): # performaing the forward pass through all layers\n",
    "        # images: 64, 1, 28, 28\n",
    "        out = F.relu(self.layer1(images))\n",
    "        # out: 64, 5, 28, 28\n",
    "        out = F.relu(self.layer2(out))\n",
    "        # out : 64, 10, 28, 28\n",
    "        out = out.reshape((-1, 10*28*28))\n",
    "        # out: 64, 7840\n",
    "        out = F.relu(self.layer3(out))\n",
    "        # out : 64, 120\n",
    "        out = F.relu(self.layer4(out))\n",
    "        # out : 64, 84\n",
    "        out = self.layer5(out)\n",
    "        # out  64, 10\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0546,  0.0691, -0.0849,  0.0201, -0.1017,  0.0348,  0.0344, -0.0485,\n",
       "         -0.0676,  0.0188],\n",
       "        [ 0.0457,  0.0686, -0.0800,  0.0169, -0.0980,  0.0329,  0.0417, -0.0505,\n",
       "         -0.0767,  0.0246],\n",
       "        [ 0.0448,  0.0721, -0.1040,  0.0236, -0.1050,  0.0373,  0.0392, -0.0596,\n",
       "         -0.0855,  0.0192],\n",
       "        [ 0.0451,  0.0727, -0.1094,  0.0184, -0.1128,  0.0382,  0.0360, -0.0636,\n",
       "         -0.0870,  0.0115],\n",
       "        [ 0.0506,  0.0687, -0.1057,  0.0287, -0.1126,  0.0467,  0.0324, -0.0593,\n",
       "         -0.0838,  0.0148],\n",
       "        [ 0.0410,  0.0706, -0.0810,  0.0125, -0.1033,  0.0345,  0.0440, -0.0478,\n",
       "         -0.0744,  0.0206],\n",
       "        [ 0.0552,  0.0701, -0.0903,  0.0255, -0.1027,  0.0360,  0.0273, -0.0509,\n",
       "         -0.0818,  0.0184],\n",
       "        [ 0.0441,  0.0743, -0.0888,  0.0118, -0.1078,  0.0360,  0.0368, -0.0474,\n",
       "         -0.0748,  0.0177],\n",
       "        [ 0.0520,  0.0677, -0.0879,  0.0240, -0.0982,  0.0375,  0.0301, -0.0477,\n",
       "         -0.0733,  0.0115],\n",
       "        [ 0.0407,  0.0728, -0.0810,  0.0154, -0.0999,  0.0312,  0.0425, -0.0458,\n",
       "         -0.0716,  0.0239],\n",
       "        [ 0.0304,  0.0757, -0.0961,  0.0177, -0.1063,  0.0300,  0.0500, -0.0593,\n",
       "         -0.0830,  0.0214],\n",
       "        [ 0.0500,  0.0707, -0.0863,  0.0162, -0.1040,  0.0275,  0.0364, -0.0508,\n",
       "         -0.0786,  0.0223],\n",
       "        [ 0.0413,  0.0716, -0.0918,  0.0152, -0.1072,  0.0318,  0.0407, -0.0543,\n",
       "         -0.0873,  0.0220],\n",
       "        [ 0.0547,  0.0694, -0.0910,  0.0172, -0.0981,  0.0373,  0.0355, -0.0554,\n",
       "         -0.0815,  0.0211],\n",
       "        [ 0.0532,  0.0664, -0.0907,  0.0195, -0.1049,  0.0360,  0.0322, -0.0532,\n",
       "         -0.0801,  0.0134],\n",
       "        [ 0.0373,  0.0785, -0.1101,  0.0091, -0.1124,  0.0346,  0.0334, -0.0608,\n",
       "         -0.0889,  0.0088],\n",
       "        [ 0.0515,  0.0693, -0.0849,  0.0176, -0.1059,  0.0301,  0.0405, -0.0560,\n",
       "         -0.0854,  0.0226],\n",
       "        [ 0.0404,  0.0761, -0.1077,  0.0150, -0.1182,  0.0381,  0.0379, -0.0620,\n",
       "         -0.0925,  0.0151],\n",
       "        [ 0.0468,  0.0726, -0.0940,  0.0204, -0.1031,  0.0341,  0.0356, -0.0588,\n",
       "         -0.0784,  0.0176],\n",
       "        [ 0.0423,  0.0676, -0.1022,  0.0243, -0.1108,  0.0400,  0.0312, -0.0543,\n",
       "         -0.0836,  0.0074],\n",
       "        [ 0.0440,  0.0728, -0.0975,  0.0228, -0.1069,  0.0368,  0.0397, -0.0559,\n",
       "         -0.0732,  0.0164],\n",
       "        [ 0.0523,  0.0644, -0.0826,  0.0218, -0.1060,  0.0395,  0.0424, -0.0586,\n",
       "         -0.0832,  0.0265],\n",
       "        [ 0.0462,  0.0709, -0.0846,  0.0159, -0.1017,  0.0336,  0.0421, -0.0494,\n",
       "         -0.0759,  0.0237],\n",
       "        [ 0.0568,  0.0661, -0.0952,  0.0229, -0.1131,  0.0368,  0.0310, -0.0549,\n",
       "         -0.0836,  0.0167],\n",
       "        [ 0.0439,  0.0737, -0.0839,  0.0153, -0.1010,  0.0291,  0.0426, -0.0498,\n",
       "         -0.0745,  0.0242],\n",
       "        [ 0.0568,  0.0662, -0.0884,  0.0213, -0.1005,  0.0371,  0.0294, -0.0503,\n",
       "         -0.0780,  0.0256],\n",
       "        [ 0.0567,  0.0706, -0.0826,  0.0211, -0.1037,  0.0302,  0.0361, -0.0531,\n",
       "         -0.0817,  0.0232],\n",
       "        [ 0.0483,  0.0691, -0.0936,  0.0172, -0.0999,  0.0374,  0.0371, -0.0606,\n",
       "         -0.0895,  0.0245],\n",
       "        [ 0.0436,  0.0719, -0.0985,  0.0169, -0.1069,  0.0355,  0.0454, -0.0598,\n",
       "         -0.0841,  0.0266],\n",
       "        [ 0.0598,  0.0677, -0.0897,  0.0262, -0.1101,  0.0384,  0.0293, -0.0511,\n",
       "         -0.0833,  0.0192],\n",
       "        [ 0.0484,  0.0688, -0.0895,  0.0185, -0.1029,  0.0397,  0.0380, -0.0511,\n",
       "         -0.0750,  0.0190],\n",
       "        [ 0.0517,  0.0714, -0.0837,  0.0156, -0.1044,  0.0307,  0.0366, -0.0529,\n",
       "         -0.0843,  0.0227]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "kyi_model = Kyi_CNN()\n",
    "output = kyi_model(images)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = torch.tensor ([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952444\n"
     ]
    }
   ],
   "source": [
    "# counting the parameters\n",
    "total_num_of_params = 0\n",
    "for param in kyi_model.parameters():\n",
    "    total_num_of_params += param.numel()\n",
    "    \n",
    "print(total_num_of_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(kyi_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 0.0516420342028141\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1\n",
    "# 1. loop epoch\n",
    "for i in range (num_epoch):\n",
    "    \n",
    "    # 2. loop train loader\n",
    "    for images, labels in train_loader:\n",
    "        \n",
    "        # 3. predict / forward pass\n",
    "        yhat = kyi_model(images)\n",
    "    \n",
    "        # 4. calculate loss\n",
    "        loss = criterion(yhat, labels)\n",
    "        \n",
    "        # 5. calculate gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "    \n",
    "        # 6. update weight\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"epoch: {num_epoch} | loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss: 0.03662089630961418\n"
     ]
    }
   ],
   "source": [
    "kyi_model.eval() # this will turn off dropout, batch norm\n",
    "with torch.no_grad(): # this will turn off gradient calculations\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        # 1. predict\n",
    "        y_hat = kyi_model(images)\n",
    "        # 2. loss\n",
    "        loss = criterion(y_hat, labels)\n",
    "        \n",
    "print(\"Cross Entropy Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 10]), torch.Size([32]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_pred = torch.max(y_hat, 1)[1]\n",
    "y_hat_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 3, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 6, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 3, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 3, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 3, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 4]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_hat_pred, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(np.transpose(test_data[0][0], (1,2,0)))\n",
    "# check what is out testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = kyi_model(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.8513, -1.0008, -1.6093,  8.8014, -9.6364, 10.6108, -7.1766, -2.0530,\n",
       "         -1.0095,  3.1170]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred\n",
    "# highest is the prediction one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
