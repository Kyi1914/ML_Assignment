{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "print (data.feature_names)\n",
    "\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Specifying input and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change numpy to torch\n",
    "train_input  = torch.tensor (X_train, dtype = torch.float32)\n",
    "test_input   = torch.tensor (X_test, dtype = torch.float32)\n",
    "train_output = torch.tensor (y_train, dtype = torch.float32)\n",
    "test_output  = torch.tensor (y_test, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([296, 10]),\n",
       " torch.Size([146, 10]),\n",
       " torch.Size([296]),\n",
       " torch.Size([146]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape, test_input.shape, train_output.shape, test_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, torch.float32, torch.float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.dtype, test_input.dtype, train_output.dtype, test_output.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "print (data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset (train_input, train_output)\n",
    "test_ds  = TensorDataset (test_input, test_output)\n",
    "# train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n296 / 32 = 10 rounds\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\",len(train_ds))\n",
    "296 / 32\n",
    "'''\n",
    "\n",
    "296 / 32 = 10 rounds\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # binary \n",
    "train_dl = DataLoader (train_ds, batch_size = batch_size, shuffle = True,  num_workers = 4)\n",
    "test_dl  = DataLoader (test_ds,  batch_size = batch_size, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# for batch_x, batch_y in train_dl:\n",
    "#     print (\"One batch of X:\", batch_x.shape)\n",
    "#     print (\"One batch of y:\", batch_y.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear (10, 24), # 10 features in the dataset\n",
    "    nn.ReLU(), # gradient = 1\n",
    "    # nn.Sigmoid () >> allow us to learn non-linear funciton - activation function\n",
    "    nn.Linear (24, 12),\n",
    "    nn.ReLU(), # you can use this instead of Sigmoid: tanh, relu, leakly, swinrelu, etc.\n",
    "    nn.Linear (12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear (6, 1)\n",
    ")\n",
    "\n",
    "# any number of matrix mautiplication can be approximate into one matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n",
      "24\n",
      "288\n",
      "12\n",
      "72\n",
      "6\n",
      "6\n",
      "1\n",
      "649\n"
     ]
    }
   ],
   "source": [
    "total_num_of_params = 0\n",
    "for ix, p in enumerate(model.parameters()):\n",
    "    # print (p.shape)\n",
    "    print (p.numel()) # total number in layer: [10, 24] = 240 | bias = 24\n",
    "    total_num_of_params += p.numel()\n",
    "print (total_num_of_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always good to test your neural network before training\n",
    "yhat = model(train_input)\n",
    "yhat.shape\n",
    "assert yhat.shape[1] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD (model.parameters(), lr = 0.0001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 39314.57\n",
      "Epoch: 1 | Loss: 29296.86\n",
      "Epoch: 2 | Loss: 36494.19\n",
      "Epoch: 3 | Loss: 29096.76\n",
      "Epoch: 4 | Loss: 27859.09\n"
     ]
    }
   ],
   "source": [
    "# ## Putting them together - actually learning!\n",
    "\n",
    "# basically same as linear / logistic regression\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range (num_epochs):\n",
    "    \n",
    "    for batch_x, batch_y in train_dl:\n",
    "        \n",
    "        batch_x.to (device)\n",
    "        batch_y.to (device)\n",
    "        batch_y = batch_y.reshape (-1,1) #(m,1) ==> \n",
    "        \n",
    "        # 2.1 Predict\n",
    "        yhat = model (batch_x)\n",
    "        \n",
    "        # 2.2 Calculate loss\n",
    "        loss = criterion (yhat, batch_y)\n",
    "        \n",
    "        # 2.3 Calculate gradients\n",
    "        optimizer .zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "    print (f\"Epoch: {epoch} | Loss: {loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model\n",
    "filename = 'model/diabetes.pth'\n",
    "torch.save (model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24884.0039)\n",
      "tensor(29758.6016)\n",
      "tensor(27268.7578)\n",
      "tensor(33819.4492)\n",
      "tensor(28912.0859)\n",
      "Trotal Average MSE =  28928.579687499998\n"
     ]
    }
   ],
   "source": [
    "model.eval() # change the model to eval mode 0 it will not keep the gradients, it will skip dropout, batch \n",
    "\n",
    "total_avg_mse = 0\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for batch_x, batch_y in test_dl:\n",
    "        \n",
    "        yhat = model(batch_x)\n",
    "        batch_y = batch_y.reshape((-1, 1))\n",
    "        mse  = criterion (yhat, batch_y)\n",
    "        \n",
    "        print (mse)\n",
    "        total_avg_mse += mse.item() / len (test_dl)\n",
    "        \n",
    "        \n",
    "    print (\"Trotal Average MSE = \", total_avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
